{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model's train/val/test preds and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = \"regressionJun24Positives\"\n",
    "\n",
    "trainPredictions = open('../predictions/' + model + '/trainPredictions.txt')\n",
    "validPredictions = open('../predictions/' + model + '/validPredictions.txt')\n",
    "testPredictions = open('../predictions/' + model + '/testPredictions.txt')\n",
    "\n",
    "trainPreds = {'avg': [], 'rep1': [], 'rep2': []}\n",
    "validPreds = {'avg': [], 'rep1': [], 'rep2': []}\n",
    "testPreds = {'avg': [], 'rep1': [], 'rep2': []}\n",
    "\n",
    "for line in trainPredictions:\n",
    "    line = line.strip().split('\\t')\n",
    "    trainPreds['avg'].append(float(line[0]))\n",
    "    trainPreds['rep1'].append(float(line[1]))\n",
    "    trainPreds['rep2'].append(float(line[2]))\n",
    "    \n",
    "for line in validPredictions:\n",
    "    line = line.strip().split('\\t')\n",
    "    validPreds['avg'].append(float(line[0]))\n",
    "    validPreds['rep1'].append(float(line[1]))\n",
    "    validPreds['rep2'].append(float(line[2]))\n",
    "    \n",
    "for line in testPredictions:\n",
    "    line = line.strip().split('\\t')\n",
    "    testPreds['avg'].append(float(line[0]))\n",
    "    testPreds['rep1'].append(float(line[1]))\n",
    "    testPreds['rep2'].append(float(line[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "model = \"regressionJun24Positives\"\n",
    "trainHdf5 = h5py.File('../hdf5files/' + model + '/train_data.hdf5')\n",
    "validHdf5 = h5py.File('../hdf5files/' + model + '/valid_data.hdf5')\n",
    "testHdf5 = h5py.File('../hdf5files/' + model + '/test_data.hdf5')\n",
    "\n",
    "trainLabels = {'avg': [], 'rep1': [], 'rep2': []}\n",
    "validLabels = {'avg': [], 'rep1': [], 'rep2': []}\n",
    "testLabels = {'avg': [], 'rep1': [], 'rep2': []}\n",
    "\n",
    "for label in trainHdf5['Y']['output']:\n",
    "    trainLabels['avg'].append(label[0])\n",
    "    trainLabels['rep1'].append(label[1])\n",
    "    trainLabels['rep2'].append(label[2])\n",
    "    \n",
    "for label in validHdf5['Y']['output']:\n",
    "    validLabels['avg'].append(label[0])\n",
    "    validLabels['rep1'].append(label[1])\n",
    "    validLabels['rep2'].append(label[2])\n",
    "\n",
    "for label in testHdf5['Y']['output']:\n",
    "    testLabels['avg'].append(label[0])\n",
    "    testLabels['rep1'].append(label[1])\n",
    "    testLabels['rep2'].append(label[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for predDict in [trainPreds, validPreds, testPreds, trainLabels, validLabels, testLabels]:\n",
    "    predDict['avg'] = np.array(predDict['avg'])\n",
    "    predDict['rep1'] = np.array(predDict['rep1'])\n",
    "    predDict['rep2'] = np.array(predDict['rep2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr\n",
    "print \"Avg signal predictions Pearson = \" + str(pearsonr(validPreds['avg'], validLabels['avg']))\n",
    "print \"Avg signal predictions Spearman = \" + str(spearmanr(validPreds['avg'], validLabels['avg']))\n",
    "print \"Rep1 signal predictions Pearson = \" + str(pearsonr(validPreds['rep1'], validLabels['rep1']))\n",
    "print \"Rep1 signal predictions Spearman = \" + str(spearmanr(validPreds['rep1'], validLabels['rep1']))\n",
    "print \"Rep2 signal predictions Pearson = \" + str(pearsonr(validPreds['rep2'], validLabels['rep2']))\n",
    "print \"Rep2 signal predictions Spearman = \" + str(spearmanr(validPreds['rep2'], validLabels['rep2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot labels vs. predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plt.subplot(111);\n",
    "plt.figure();\n",
    "plt.title('Average Replicate Signal, Training Set');\n",
    "g = sns.regplot(trainLabels['avg'], trainPreds['avg']);\n",
    "g.set(xlabel='y_true', ylabel='y_pred');\n",
    "plt.show()\n",
    "# g.set_xlim(0, 250);\n",
    "\n",
    "# plt.subplot(122);\n",
    "plt.figure();\n",
    "plt.title('Replicate 1 Signal, Training Set');\n",
    "g = sns.regplot(trainLabels['rep1'], trainPreds['rep1']);\n",
    "g.set(xlabel='y_true', ylabel='y_pred');\n",
    "plt.show()\n",
    "# g.set_xlim(0, 250);\n",
    "\n",
    "# plt.subplot(133);\n",
    "plt.figure();\n",
    "plt.title('Replicate 2 Signal, Training Set');\n",
    "g = sns.regplot(trainLabels['rep2'], trainPreds['rep2']);\n",
    "g.set(xlabel='y_true', ylabel='y_pred');\n",
    "plt.show()\n",
    "# g.set_xlim(0, 250);\n",
    "\n",
    "# plt.subplot(214);\n",
    "# plt.title('Average Replicate Signal, Validation Set');\n",
    "# g = sns.regplot(validLabels['avg'], validPreds['avg']);\n",
    "# g.set(xlabel='y_true', ylabel='y_pred');\n",
    "# g.set_xlim(0, 250);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plt.subplot(111);\n",
    "plt.figure();\n",
    "plt.title('Average Replicate Signal, Validation Set');\n",
    "g = sns.regplot(validLabels['avg'], validPreds['avg']);\n",
    "g.set(xlabel='y_true', ylabel='y_pred');\n",
    "sns.plt.show()\n",
    "# g.set_xlim(0, 250);\n",
    "\n",
    "# plt.subplot(122);\n",
    "plt.figure();\n",
    "plt.title('Replicate 1 Signal, Validation Set');\n",
    "g = sns.regplot(validLabels['rep1'], validPreds['rep1']);\n",
    "g.set(xlabel='y_true', ylabel='y_pred');\n",
    "sns.plt.show()\n",
    "# g.set_xlim(0, 250);\n",
    "\n",
    "# plt.subplot(133);\n",
    "plt.figure();\n",
    "plt.title('Replicate 2 Signal, Validation Set');\n",
    "g = sns.regplot(validLabels['rep2'], validPreds['rep2']);\n",
    "g.set(xlabel='y_true', ylabel='y_pred');\n",
    "sns.plt.show()\n",
    "# g.set_xlim(0, 250);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plt.subplot(111);\n",
    "plt.figure();\n",
    "plt.title('Average Replicate Signal, Test Set');\n",
    "g = sns.regplot(testLabels['avg'], testPreds['avg']);\n",
    "g.set(xlabel='y_true', ylabel='y_pred');\n",
    "sns.plt.show()\n",
    "# g.set_xlim(0, 250);\n",
    "\n",
    "# plt.subplot(122);\n",
    "plt.figure();\n",
    "plt.title('Replicate 1 Signal, Test Set');\n",
    "g = sns.regplot(testLabels['rep1'], testPreds['rep1']);\n",
    "g.set(xlabel='y_true', ylabel='y_pred');\n",
    "sns.plt.show()\n",
    "# g.set_xlim(0, 250);\n",
    "\n",
    "# plt.subplot(133);\n",
    "plt.figure();\n",
    "plt.title('Replicate 2 Signal, Test Set');\n",
    "g = sns.regplot(testLabels['rep2'], testPreds['rep2']);\n",
    "g.set(xlabel='y_true', ylabel='y_pred');\n",
    "sns.plt.show()\n",
    "# g.set_xlim(0, 250);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluate performance at TSS regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "gencodeFilePath = \"../../data/GENCODE/gencodeTSS/TSS_human_strict_with_gencodetss_notlow_ext50eachside_merged_withgenctsscoord_andgnlist.gff.gz\"\n",
    "tssFile = gzip.open(gencodeFilePath)\n",
    "\n",
    "gencCageTss = []\n",
    "for line in tssFile:\n",
    "    line = line.strip().split('\\t')\n",
    "    annot = line[8].strip().split(' ')\n",
    "    if annot[1] == \"GencCAGE\" or annot[1] == \"GencOnly\" or annot[1] == \"CAGEOnly\":\n",
    "        gencCageTss.append(line)\n",
    "\n",
    "print len(gencCageTss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chr8Tss = []\n",
    "for tss in gencCageTss:\n",
    "    if tss[0] == 'chr8':\n",
    "        chr8Tss.append(tss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(chr8Tss)\n",
    "for i in range(len(chr8Tss)):\n",
    "    chr8Tss[i][3] = int(chr8Tss[i][3])\n",
    "    chr8Tss[i][4] = int(chr8Tss[i][4])\n",
    "\n",
    "print chr8Tss[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "testRegionsFile = gzip.open('../splits/regressionJun24Positives/testJun24RegressionPositives.txt.gz')\n",
    "testRegions = []\n",
    "i = 0\n",
    "for line in testRegionsFile:\n",
    "    line = line.strip()\n",
    "    chrom, coords = line.split(':')\n",
    "    if coords.rfind('-') == coords.find('-'):\n",
    "        start, end = coords.split('-')\n",
    "        strand = end.split('(')[1][0]\n",
    "        end = end[:end.find('(')]\n",
    "    else:\n",
    "        start, end = coords.split('-')[:2]\n",
    "        end = end[:-1]\n",
    "        strand = line.split('(')[1][0]\n",
    "    testRegions.append([chrom, int(start), int(end), strand])\n",
    "    if i < 5:\n",
    "        print chrom, start, end, strand\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(testRegions)\n",
    "print testRegions[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minDistance = 1000\n",
    "\n",
    "tssProximalRegionIndices = []\n",
    "i = 0\n",
    "for i in range(len(testRegions)):\n",
    "    if i % 5e3 == 0:\n",
    "        print i\n",
    "    fragment = testRegions[i]\n",
    "    fragmentStart = fragment[1]\n",
    "    fragmentEnd = fragment[2]\n",
    "    for j in range(len(chr8Tss)):\n",
    "        tss = chr8Tss[j]\n",
    "        tssStart = tss[3]\n",
    "        tssEnd = tss[4]\n",
    "        \n",
    "        # compare chromosomes; if TSS is past it, break, else keep looking\n",
    "        if int(tss[0].split('chr')[1]) > int(fragment[0].split('chr')[1]):\n",
    "            break\n",
    "        elif int(tss[0].split('chr')[1]) < int(fragment[0].split('chr')[1]):\n",
    "            continue\n",
    "        \n",
    "        # compare genomic coordinates\n",
    "        if tssStart > fragmentEnd + minDistance:\n",
    "            break\n",
    "        elif tssEnd + minDistance < fragmentStart:\n",
    "            continue\n",
    "        else:\n",
    "            tssProximalRegionIndices.append((i, j))\n",
    "            break\n",
    "    \n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('../data/evaluation/regressionJun24_testFragmentsNearGencOrCageTss.txt', 'w')\n",
    "f.write(\"testFragmentIndex\\tTssIndex\\n\")\n",
    "for pair in tssProximalRegionIndices:\n",
    "    f.write(str(pair[0]) + '\\t' + str(pair[1]) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tssProximalRegionIndices = []\n",
    "f = open('../data/evaluation/regressionJun24_testFragmentsNearGencOrCageTss.txt')\n",
    "f.readline()\n",
    "for pair in f:\n",
    "    pair = pair.strip().split('\\t')\n",
    "    tssProximalRegionIndices.append((int(pair[0]), int(pair[1])))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(tssProximalRegionIndices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tssProximalRegions = np.array([i for (i,j) in tssProximalRegionIndices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "# Data quality near TSSs\n",
    "print spearmanr(testLabels['rep1'], testLabels['rep2'])\n",
    "print spearmanr(testLabels['rep1'][tssProximalRegions], testLabels['rep2'][tssProximalRegions])\n",
    "# Pearson correlation as they report in their paper... sneaky\n",
    "print pearsonr(testLabels['rep1'], testLabels['rep2'])\n",
    "print pearsonr(testLabels['rep1'][tssProximalRegions], testLabels['rep2'][tssProximalRegions])\n",
    "\n",
    "# Prediction scores near TSSs\n",
    "print spearmanr(testPreds['avg'], testLabels['avg'])\n",
    "print spearmanr(testPreds['avg'][tssProximalRegions], testLabels['avg'][tssProximalRegions])\n",
    "print spearmanr(testPreds['rep1'], testLabels['rep1'])\n",
    "print spearmanr(testPreds['rep1'][tssProximalRegions], testLabels['rep1'][tssProximalRegions])\n",
    "print spearmanr(testPreds['rep2'], testLabels['rep2'])\n",
    "print spearmanr(testPreds['rep2'][tssProximalRegions], testLabels['rep2'][tssProximalRegions])\n",
    "\n",
    "# Prediction Pearson correlations near TSSs\n",
    "print pearsonr(testPreds['avg'], testLabels['avg'])\n",
    "print pearsonr(testPreds['avg'][tssProximalRegions], testLabels['avg'][tssProximalRegions])\n",
    "print pearsonr(testPreds['rep1'], testLabels['rep1'])\n",
    "print pearsonr(testPreds['rep1'][tssProximalRegions], testLabels['rep1'][tssProximalRegions])\n",
    "print pearsonr(testPreds['rep2'], testLabels['rep2'])\n",
    "print pearsonr(testPreds['rep2'][tssProximalRegions], testLabels['rep2'][tssProximalRegions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we reproduce reported correlations of SuRE signal and TSS strength?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr8 19275 20358 +\n",
      "chr8 25462 26395 +\n",
      "chr8 28827 29718 +\n",
      "chr8 29095 30084 -\n",
      "chr8 29302 29804 +\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "\n",
    "testRegionsFile = gzip.open('../splits/regressionJun24Positives/testJun24RegressionPositives.txt.gz')\n",
    "testRegions = []\n",
    "i = 0\n",
    "for line in testRegionsFile:\n",
    "    line = line.strip()\n",
    "    chrom, coords = line.split(':')\n",
    "    if coords.rfind('-') == coords.find('-'):\n",
    "        start, end = coords.split('-')\n",
    "        strand = end.split('(')[1][0]\n",
    "        end = end[:end.find('(')]\n",
    "    else:\n",
    "        start, end = coords.split('-')[:2]\n",
    "        end = end[:-1]\n",
    "        strand = line.split('(')[1][0]\n",
    "    testRegions.append([chrom, int(start), int(end), strand])\n",
    "    if i < 5:\n",
    "        print chrom, start, end, strand\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "# gencodeFilePath = \"../../data/GENCODE/gencodeTSS/RAMPAGE_TSS_ENCFF069ZON_hg19converted_idrPeaks.bed\"\n",
    "# tssFile = open(gencodeFilePath)\n",
    "\n",
    "# rampageTss = []\n",
    "# for line in tssFile:\n",
    "#     line = line.strip().split('\\t')\n",
    "#     rampageTss.append(line)\n",
    "\n",
    "# chr8RampageTss = []\n",
    "# for tss in rampageTss:\n",
    "#     if tss[0] == 'chr8':\n",
    "#         chr8RampageTss.append(tss)\n",
    "\n",
    "gencodeFilePath = \"../../data/GENCODE/gencodeTSS/fantom5.cage.strict.hg19.bed.gz\"\n",
    "tssFile = gzip.open(gencodeFilePath)\n",
    "\n",
    "rampageTss = []\n",
    "for line in tssFile:\n",
    "    line = line.strip().split(' ')\n",
    "    rampageTss.append(line)\n",
    "\n",
    "chr8RampageTss = []\n",
    "for tss in rampageTss:\n",
    "    if tss[0] == 'chr8':\n",
    "        chr8RampageTss.append(tss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217572\n",
      "8789\n"
     ]
    }
   ],
   "source": [
    "print len(rampageTss)\n",
    "print len(chr8RampageTss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-59170ac7362a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchr8RampageTss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr8RampageTss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mchr8RampageTss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import np\n",
    "chr8RampageTss = np.array(chr8RampageTss)\n",
    "print chr8RampageTss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "maxDistance = 2000 # 2kb, as in the paper\n",
    "sureRampagePairs = []\n",
    "i = 0\n",
    "for (i, fragment) in enumerate(testRegions):\n",
    "    if i % 5e3 == 0:\n",
    "        print i\n",
    "    fragmentStart = fragment[1]\n",
    "    fragmentEnd = fragment[2]\n",
    "    for (j, tss) in enumerate(chr8RampageTss):\n",
    "        tssStart = int(tss[1])\n",
    "        tssEnd = int(tss[2])\n",
    "#         print tssStart\n",
    "#         print tssEnd\n",
    "#         break\n",
    "        \n",
    "        # compare chromosomes; if TSS is past it, break, else keep looking\n",
    "        if int(tss[0].split('chr')[1]) > int(fragment[0].split('chr')[1]):\n",
    "            break\n",
    "        elif int(tss[0].split('chr')[1]) < int(fragment[0].split('chr')[1]):\n",
    "            continue\n",
    "        \n",
    "        # compare genomic coordinates\n",
    "        if tssStart > fragmentEnd + maxDistance:\n",
    "            break\n",
    "        elif tssEnd + maxDistance < fragmentStart:\n",
    "            continue\n",
    "        else:\n",
    "            sureRampagePairs.append((i, j))\n",
    "            break\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print len(sureRampagePairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "model = \"regressionJun24Positives\"\n",
    "testHdf5 = h5py.File('../hdf5files/' + model + '/test_data.hdf5')\n",
    "testLabels = {'avg': [], 'rep1': [], 'rep2': []}\n",
    "\n",
    "for label in testHdf5['Y']['output']:\n",
    "    testLabels['avg'].append(label[0])\n",
    "    testLabels['rep1'].append(label[1])\n",
    "    testLabels['rep2'].append(label[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sureIndices = np.array([i for (i,j) in sureRampagePairs])\n",
    "rampageIndices = np.array([j for (i,j) in sureRampagePairs])\n",
    "sureSignals = np.array([testLabels['rep2'][idx] for idx in sureIndices])\n",
    "# avgRampageSignals = (chr8RampageTss[:, 10].astype(np.float) + chr8RampageTss[:, 13].astype(np.float))/2\n",
    "cageSignals = chr8RampageTss[:, 4].astype(np.float)\n",
    "rampageSignals = np.array([cageSignals[idx] for idx in rampageIndices]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print spearmanr(sureSignals, rampageSignals)\n",
    "print pearsonr(sureSignals, rampageSignals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluate model predictions of RAMPAGE TSS strengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51838, 2000, 4)\n",
      "949\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "model = \"regressionJun24Positives\"\n",
    "validHdf5 = h5py.File('../hdf5files/' + model + '/valid_data.hdf5')\n",
    "\n",
    "print validHdf5['X']['sequence'].shape\n",
    "# avgLength = int(np.sum(validHdf5['X']['sequence']) / validHdf5['X']['sequence'].shape[0])\n",
    "print avgLength\n",
    "# print np.mean(np.sum(validHdf5['X']['sequence'], axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rampageFile = open(\"../../data/GENCODE/gencodeTSS/RAMPAGE_TSS_ENCFF069ZON_hg19converted_idrPeaks.bed\")\n",
    "valTestTssRegions = open(\"../data/evaluation/rampageTssExpandedBedRegionsValTest.bed\", 'w')\n",
    "allTssRegions = open(\"../data/evaluation/rampageTssExpandedBedRegionsAll.bed\", 'w')\n",
    "\n",
    "rampageNewTssCoords = open('../data/evaluation/rampageLabelsWithTssMappings.txt', 'w')\n",
    "rampageNewTssCoords.write('chr\\texpandedStart\\texpandedEnd\\tavgScore\\trep1Score\\trep2Score\\ttssStart\\ttssEnd\\n')\n",
    "\n",
    "rampageStrengths = {}\n",
    "fractionDownstream = 0.1\n",
    "for line in rampageFile:\n",
    "    line = line.strip().split('\\t')\n",
    "    chrom = line[0]\n",
    "    if len(chrom) > 5:\n",
    "        continue\n",
    "        \n",
    "    tssLen = int(line[2]) - int(line[1])\n",
    "    if tssLen < avgLength:\n",
    "        end = int(line[2]) + int((avgLength - tssLen) * fractionDownstream)\n",
    "        start = int(line[1]) - int((avgLength - tssLen) * (1 - fractionDownstream))\n",
    "    score1 = float(line[10])\n",
    "    score2 = float(line[13])\n",
    "    avgScore = (score1 + score2) / 2\n",
    "    \n",
    "    tss = line[0] + '\\t' + str(start) + '\\t' + str(end)\n",
    "    rampageStrengths[tss] = [avgScore, score1, score2]\n",
    "    rampageNewTssCoords.write(tss + '\\t' + '\\t'.join([str(x) for x in rampageStrengths[tss]]) + '\\t' + line[1] + '\\t' + line[2] + '\\n')\n",
    "    \n",
    "    if chrom == 'chr8' or chrom == 'chr18':\n",
    "        valTestTssRegions.write(tss + '\\t' + '.' + '\\t' + str(avgScore) + '\\n')\n",
    "    allTssRegions.write(tss + '\\t' + '.' + '\\t' + str(avgScore) + '\\n')\n",
    "\n",
    "valTestTssRegions.close()\n",
    "allTssRegions.close()\n",
    "rampageNewTssCoords.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr16\t24550061\t24551009\n",
      "[47.0, 65.0, 29.0]\n"
     ]
    }
   ],
   "source": [
    "print rampageStrengths.keys()[0]\n",
    "print rampageStrengths[rampageStrengths.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create array of sequences\n",
    "from avutils import util\n",
    "\n",
    "def get_padded_X_array(fasta, padded_length = 2000):\n",
    "    seqs = open(fasta).readlines()\n",
    "    seqNames = []\n",
    "    oneHotSequences = np.zeros(shape = (len(seqs)/2, padded_length, 4))\n",
    "    for (i, line) in enumerate(seqs):\n",
    "        if i % 2 == 0:\n",
    "            line = line.strip().split('>')[1]\n",
    "            chrom = line.split(':')[0]\n",
    "            coords = line.split(':')[1]\n",
    "            start, end = coords.split('-')\n",
    "            seqNames.append(chrom + '\\t' + start + '\\t' + end)\n",
    "        else:\n",
    "            seqStr = line.strip()\n",
    "            seqOneHot = util.seq_to_one_hot(seqStr)\n",
    "            remainingLength = padded_length - len(seqStr)\n",
    "            if len(seqStr) % 2 == 1:\n",
    "                padSize = (remainingLength/2, remainingLength/2 + 1)\n",
    "            else:\n",
    "                padSize = (remainingLength/2, remainingLength/2)\n",
    "            \n",
    "            seqOneHotPadded = np.pad(seqOneHot, \n",
    "                                     pad_width = (padSize, (0, 0)), \n",
    "                                     mode = 'constant')\n",
    "#             print seqOneHot[:10]\n",
    "#             print np.sum(seqOneHotPadded[526:1474] - seqOneHot)\n",
    "#             print seqOneHot.shape\n",
    "#             print np.sum(seqOneHot)\n",
    "#             print seqOneHotPadded.shape\n",
    "#             print np.sum(seqOneHotPadded)\n",
    "            oneHotSequences[i/2] = seqOneHotPadded \n",
    "#             break\n",
    "    \n",
    "    return (seqNames, oneHotSequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seqNames, X_test = get_padded_X_array('../data/evaluation/rampageExpandedTssAllChrsSequences.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8584, 2000, 4)\n"
     ]
    }
   ],
   "source": [
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "ERROR (theano.gpuarray): Could not initialize pygpu, support disabled\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/rmovva/anaconda2/envs/mommadragonn/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 164, in <module>\n",
      "    use(config.device)\n",
      "  File \"/home/users/rmovva/anaconda2/envs/mommadragonn/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 151, in use\n",
      "    init_dev(device)\n",
      "  File \"/home/users/rmovva/anaconda2/envs/mommadragonn/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 60, in init_dev\n",
      "    sched=config.gpuarray.sched)\n",
      "  File \"pygpu/gpuarray.pyx\", line 614, in pygpu.gpuarray.init (pygpu/gpuarray.c:9415)\n",
      "  File \"pygpu/gpuarray.pyx\", line 566, in pygpu.gpuarray.pygpu_init (pygpu/gpuarray.c:9106)\n",
      "  File \"pygpu/gpuarray.pyx\", line 1021, in pygpu.gpuarray.GpuContext.__cinit__ (pygpu/gpuarray.c:13468)\n",
      "GpuArrayException: Error loading library: -1\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json, model_from_yaml\n",
    "import json\n",
    "\n",
    "modelID = \"record_2_model_Yjv2n_\"\n",
    "\n",
    "json_path = \"../model_files/regressionJun24Positives/\" + modelID + \"modelJson.json\"\n",
    "with open(json_path) as json_file:\n",
    "    json_string = json.dumps(json.load(json_file))\n",
    "    model = model_from_json(json_string)  \n",
    "\n",
    "model.load_weights(\"../model_files/regressionJun24Positives/\" + modelID + \"modelWeights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 8584 predictions took 434.4366s.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "y_test = model.predict(X_test, batch_size = 16)\n",
    "print \"Generating \" + str(len(X_test)) + \" predictions took \" + str(round(time.time() - t0, 4)) + \"s.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = []\n",
    "for seqName in seqNames:\n",
    "    y_true.append(rampageStrengths[seqName])\n",
    "    \n",
    "y_true = np.array(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.2664470872982907, pvalue=1.8889752743166938e-139)\n",
      "(0.047889751861019431, 9.0428074703439227e-06)\n",
      "SpearmanrResult(correlation=0.26681570711925312, pvalue=7.6079943182133611e-140)\n",
      "(0.051391422606738978, 1.8992095395906904e-06)\n",
      "SpearmanrResult(correlation=0.25351490495955015, pvalue=5.4677056692107888e-126)\n",
      "(0.040798750613013898, 0.00015618523935300455)\n",
      "SpearmanrResult(correlation=0.25256167013814151, pvalue=5.0111005938278695e-125)\n",
      "(0.038609378395454218, 0.00034627678843537207)\n"
     ]
    }
   ],
   "source": [
    "# columns in y_true are avgTssScore, tssScoreRep1, tssScoreRep2\n",
    "# columns in y_test are predictions for the avg SuRE score, rep1 SuRE score, and rep2 SuRE score\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "# we want correlation between replicate 2 prediction (probably most accurate) and avg TSS score\n",
    "print spearmanr(y_test[:, 2], y_true[:, 0])\n",
    "print pearsonr(y_test[:, 2], y_true[:, 0])\n",
    "\n",
    "# trying correlation with the individual TSS replicate scores, since the correlation with avg was pretty bad :(\n",
    "print spearmanr(y_test[:, 2], y_true[:, 1])\n",
    "print pearsonr(y_test[:, 2], y_true[:, 1])\n",
    "\n",
    "print spearmanr(y_test[:, 2], y_true[:, 2])\n",
    "print pearsonr(y_test[:, 2], y_true[:, 2])\n",
    "\n",
    "# not much better, let's look at prediction for avg b/w the SuRE replicates\n",
    "print spearmanr(y_test[:, 0], y_true[:, 2])\n",
    "print pearsonr(y_test[:, 0], y_true[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mommadragonn]",
   "language": "python",
   "name": "conda-env-mommadragonn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
