{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'activation_1', u'batchnormalization_1', u'convolution1d_1', u'dense_1', u'dense_2', u'dense_3', u'dropout_1', u'dropout_2', u'globalaveragepooling1d_1', u'prelu_1', u'prelu_2']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "modelID = \"record_7_model_nVKX8_\"\n",
    "weightsFileName = \"../model_files/regressionJun24Positives/\" + modelID + \"modelWeights.h5\"\n",
    "weights = h5py.File(weightsFileName, 'r')\n",
    "print weights.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 1, 4, 20)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "layer = 'convolution1d_1'\n",
    "# print np.array(weights[layer][str(layer + '_W')])\n",
    "conv1_weights = np.array(weights[layer][str(layer + '_W')])\n",
    "conv1_biases = np.array(weights[layer][str(layer + '_b')])\n",
    "print conv1_weights.shape\n",
    "print conv1_biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_data_path = \"../hdf5files/regression_jul3_strands_augmented_rep2only/valid_data.hdf5\"\n",
    "val_data = h5py.File(val_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205984, 2000, 4)\n"
     ]
    }
   ],
   "source": [
    "print val_data['X']['sequence'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took ~282.5163s for sequences 127 to 300127\n",
      "Took ~269.5758s for sequences 300110 to 600110\n",
      "Took ~260.6079s for sequences 600088 to 900088\n",
      "Took ~263.1138s for sequences 900020 to 1200020\n",
      "Took ~271.6573s for sequences 1200095 to 1500095\n",
      "Took ~270.8824s for sequences 1500154 to 1800154\n",
      "Took ~271.2648s for sequences 1800024 to 2100024\n",
      "Took ~259.1446s for sequences 2100078 to 2400078\n",
      "Took ~259.2118s for sequences 2400026 to 2700026\n",
      "Took ~265.4643s for sequences 2700100 to 3000100\n",
      "Took ~264.8328s for sequences 3000040 to 3300040\n",
      "Took ~276.565s for sequences 3300168 to 3600168\n",
      "Took ~281.2062s for sequences 3600018 to 3900018\n",
      "Took ~279.9254s for sequences 3900114 to 4200114\n",
      "Took ~274.4982s for sequences 4200102 to 4500102\n",
      "Took ~280.4731s for sequences 4500084 to 4800084\n",
      "Took ~273.964s for sequences 4800071 to 5100071\n",
      "Took ~275.6245s for sequences 5100044 to 5400044\n",
      "Took ~344.2208s for sequences 5400064 to 5700064\n",
      "Took ~574.0349s for sequences 5700044 to 6000044\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "numSequences = 6e6\n",
    "\n",
    "filter_length = conv1_weights.shape[0]\n",
    "stride = filter_length / 2\n",
    "val_sequences = []\n",
    "cnt = 0\n",
    "for seq in val_data['X']['sequence']:\n",
    "    if len(val_sequences) > numSequences:\n",
    "        break\n",
    "    seqLen = int(np.sum(seq))\n",
    "    \n",
    "    sliceIndices = np.arange(1000 - seqLen/2, 1000 + seqLen/2 - filter_length, stride)\n",
    "    slicer = lambda t: [t, t + filter_length]\n",
    "    sliceIndices = np.swapaxes(np.array(slicer(sliceIndices)), 0, 1)\n",
    "    \n",
    "    val_sequences += [seq[iin : iout] for iin, iout in sliceIndices]\n",
    "    print_interval = int(3e5)\n",
    "    if len(val_sequences) / print_interval > cnt / print_interval:\n",
    "        cnt += len(sliceIndices)\n",
    "        print \"Took ~\" + str(round(time.time() - t0, 4)) + \"s for sequences \" + str(cnt - print_interval) + \" to \" + str(cnt)\n",
    "        t0 = time.time()\n",
    "    else:\n",
    "        cnt += len(sliceIndices)\n",
    "#     if len(val_sequences) % 1000 == 0:\n",
    "#             cnt = len(val_sequences)\n",
    "#             print \"Took \" + str(round(time.time() - t0, 4)) + \"s for sequences \" + str(cnt-1000) + \" to \" + str(cnt)\n",
    "            \n",
    "#     for idx in startIndices:\n",
    "#         val_sequences.append(seq[idx : idx + filter_length])\n",
    "#         if len(val_sequences) % 1000 == 0:\n",
    "#             cnt = len(val_sequences)\n",
    "#             print \"Took \" + str(round(time.time() - t0, 4)) + \"s for sequences \" + str(cnt-1000) + \" to \" + str(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000044, 19, 4)\n"
     ]
    }
   ],
   "source": [
    "val_sequences = np.array(val_sequences)\n",
    "print val_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 1.159s.\n",
      "(1, 20, 6000044)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# from scipy.stats.mstats import zscore\n",
    "\n",
    "numFilters = 20\n",
    "conv1_biases_reshaped = np.broadcast_to(conv1_biases, shape = (19, 1, 4, numFilters))\n",
    "conv1_weights_plus_biases = conv1_weights + conv1_biases_reshaped\n",
    "# conv1_weights_plus_biases_normalized = zscore(conv1_weights_plus_biases, axis = None)\n",
    "\n",
    "t0 = time.time()\n",
    "filter_sequence_activations = np.tensordot(conv1_weights, val_sequences, axes = [[0, 2], [1, 2]])\n",
    "# filter_sequence_activations = np.tensordot(conv1_weights_plus_biases, val_sequences, axes = [[0, 2], [1, 2]])\n",
    "# filter_sequence_activations_normalized = np.tensordot(conv1_weights_plus_biases_normalized, val_sequences, axes = [[0, 2], [1, 2]])\n",
    "print \"Took \" + str(round(time.time() - t0, 3)) + \"s.\"\n",
    "\n",
    "print filter_sequence_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 6000044)\n"
     ]
    }
   ],
   "source": [
    "# filter_sequence_activations[i, j] will be the activation of the ith filter on the jth sequence.\n",
    "\n",
    "filter_sequence_activations = np.squeeze(filter_sequence_activations, axis=0)\n",
    "print filter_sequence_activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 6000044)\n"
     ]
    }
   ],
   "source": [
    "# normalize the filter activations so that we can use a unified activation threshold.\n",
    "from scipy.stats.mstats import zscore\n",
    "import scipy.stats as st\n",
    "\n",
    "# the \"globally\" activating sequences are sequences that strongly activate their filters overall\n",
    "# the \"locally\" activating sequences are the strongest sequences on a per-filter basis;\n",
    "# this latter type allows to construct PWMs for all the filters, while the globally activating sequences\n",
    "# only help with some PWMs\n",
    "\n",
    "# global_activation_fraction = 0.0001\n",
    "# global_activation_threshold = st.norm.ppf(1 - local_activation_fraction) # a z-score threshold for the entire array\n",
    "# filter_sequence_activations_globally_normalized = zscore(filter_sequence_activations, axis=None)\n",
    "# global_activating_sequences = np.ndarray(shape = filter_sequence_activations.shape, dtype = np.bool_)\n",
    "# global_activating_sequences = filter_sequence_activations_globally_normalized > global_activation_threshold\n",
    "# print global_activating_sequences.shape\n",
    "\n",
    "local_activation_fraction = 0.0005 # get top 1 percent of sequences for each filter; approx 10K sequences\n",
    "local_activation_threshold = st.norm.ppf(1 - local_activation_fraction)\n",
    "filter_sequence_activations_locally_normalized = zscore(filter_sequence_activations, axis=1)\n",
    "local_activating_sequences = np.ndarray(shape = filter_sequence_activations.shape, dtype = np.bool_)\n",
    "local_activating_sequences = filter_sequence_activations_locally_normalized > local_activation_threshold\n",
    "print local_activating_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local_activating_sequences_val = st.norm.cdf(filter_sequence_activations_locally_normalized) > 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   572    695   9883    421   4226   2140   3073     42   6855      5\n",
      "   3407  14019    489   3498   3322   5846   1051    500   2873   1878\n",
      "   1397   2290  96548   2007   5073    301   1684   6122    996   2464\n",
      "   1599    288   1314     42   1460    207   2728   4252     15   5072\n",
      "    241     62    550   2490   3158    174     97   1965    170    593\n",
      "    229   2485  23502     91     25    756   9006   2872 152145   1544\n",
      "     83   2457   2299   4973     86   1197   1522   1545  11668    571\n",
      "   3768  12892     30     35    108    539     34   3908  10155    119\n",
      "   3930    208   1001      5   1765   5546   5524    101   1002   7931\n",
      "   2883    981     52   6064   5545    345    266   1195      2  10657]\n",
      "[5379 3982 6610 7289 2162 6552 2188 1496 4735 1414  869 2986  799 2434 2077\n",
      " 2025 1157 1430 1979 4720]\n"
     ]
    }
   ],
   "source": [
    "print np.sum(global_activating_sequences, axis=1)\n",
    "print np.sum(local_activating_sequences, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 1, 4, 20)\n"
     ]
    }
   ],
   "source": [
    "filter_pwms = np.ndarray(shape = (19, 1, 4, numFilters))\n",
    "for i in range(filter_pwms.shape[3]):\n",
    "    filter_sequences = val_sequences[local_activating_sequences[i]]\n",
    "    filter_pwm = np.sum(filter_sequences, axis = 0) / len(filter_sequences)\n",
    "    filter_pwm = np.expand_dims(filter_pwm, axis = 1)\n",
    "    filter_pwms[:, :, :, i] = filter_pwm\n",
    "    \n",
    "print filter_pwms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.88166671870545565, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "print spearmanr(np.ravel(filter_pwms), np.ravel(conv1_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meme = open('../model_files/regression_jul3_strands_augmented/interpretation/nVKX8_20_conv_filters_meme_basset.txt', 'w')\n",
    "# background frequencies 0.2901785   0.20715891  0.20895831  0.29370428\n",
    "meme.write(\"MEME version 4\\n\\nALPHABET = ACGT\\n\\nStrands: + -\\n\\n\" +\n",
    "           \"Background letter frequencies\\nA 0.292 C 0.208 G 0.208 T 0.292\\n\\n\")\n",
    "\n",
    "filter_pwms_reaxis = np.squeeze(filter_pwms, axis = 1)\n",
    "filter_pwms_reaxis = np.swapaxes(filter_pwms_reaxis, 0, 2)\n",
    "filter_pwms_reaxis = np.swapaxes(filter_pwms_reaxis, 1, 2)\n",
    "for i in range(len(filter_pwms_reaxis)):\n",
    "    meme.write('MOTIF conv1_filter' + str(i) + '\\n')\n",
    "    meme.write('letter-probability matrix: alength= 4 w= 19\\n')\n",
    "    for j in range(len(filter_pwms_reaxis[i])):\n",
    "        meme.write(' '.join(filter_pwms_reaxis[i, j].astype(np.str)) + '\\n')\n",
    "    meme.write('\\n')\n",
    "\n",
    "meme.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000034, 19, 4)\n",
      "(100, 1000034)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 1000034 but corresponding boolean dimension is 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-9da8b75bf656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mval_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlocal_activating_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mval_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocal_activating_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 1000034 but corresponding boolean dimension is 100"
     ]
    }
   ],
   "source": [
    "print val_sequences.shape\n",
    "print local_activating_sequences.shape\n",
    "print val_sequences[local_activating_sequences[:,:]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.13218212 -3.05381727 -3.68134642 ..., -3.92485142 -4.27456188\n",
      " -3.33619428]\n"
     ]
    }
   ],
   "source": [
    "print filter_sequence_activations[0][local_activating_sequences[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 1000000)\n",
      "Took 0.806s.\n",
      "(1, 100, 1000000)\n",
      "Took 17.453s.\n"
     ]
    }
   ],
   "source": [
    "# test dot product speeds of numpy vs. theano\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "\n",
    "a = np.random.random((19,1,4,100))\n",
    "b = np.random.random((1000000,19,4))\n",
    "\n",
    "t0 = time.time()\n",
    "nptest = np.tensordot(a, b, axes = [[0, 2], [1, 2]])\n",
    "print nptest.shape\n",
    "# print nptest\n",
    "print \"Took \" + str(round(time.time() - t0, 3)) + \"s.\"\n",
    "\n",
    "t0 = time.time()\n",
    "theanotest = T.tensordot(a, b, axes = [[0, 2], [1, 2]]).eval()\n",
    "print theanotest.shape\n",
    "# print theanotest\n",
    "print \"Took \" + str(round(time.time() - t0, 3)) + \"s.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mommadragonn]",
   "language": "python",
   "name": "conda-env-mommadragonn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
