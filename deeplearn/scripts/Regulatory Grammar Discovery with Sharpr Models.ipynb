{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of active TFs by chromatin state\n",
    "\n",
    "1. Load TF PWMs (HOMER should be a good enough set)\n",
    "2. Load train sequences\n",
    "3. Load deepLIFT scores\n",
    "4. Compute PWM-deepLIFT and PWM-sequence convolution matrices using Avanti's GPU accelerated function:\n",
    "https://github.com/kundajelab/modisco_private/blob/master/test/util/test_correlation.py\n",
    "5. Divide the two matrices to \"normalize\" the PWM-deepLIFT convolution matrix. That is, the matrix entries now represent how much the motif was used by the model in making a prediction.\n",
    "6. Visualize average motif usage by chromatin state.\n",
    "7. Create a motif-motif correlation matrix to see which motifs were predictive together. Cluster this matrix to reproduce known TF interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "\n",
    "motifpwms = {}\n",
    "\n",
    "homer_path = '../../data/motifs/homer/*.motif'\n",
    "t0 = time.time()\n",
    "for homer_file in glob.glob(homer_path):\n",
    "    with open(homer_file) as f:\n",
    "        header = f.readline().strip().split('\\t')\n",
    "        name = header[1]\n",
    "        threshold = float(header[2])\n",
    "        weights = np.array(pd.read_csv(f, sep = '\\t'))\n",
    "        motifpwms[name] = weights\n",
    "print(\"Took %.3f sec to load HOMER motifs\" % (time.time() - t0))\n",
    "\n",
    "print(\"Number of PWMs: %d\" % len(motifpwms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "train_data_path = '../hdf5files/sharpr_znormed_jul23/train_data.hdf5'\n",
    "data = h5py.File(train_data_path)\n",
    "\n",
    "data_X = np.array(data['X/sequence'])\n",
    "data_Y = np.array(data['Y/output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "modelName = \"record_13_model_bgGhy_\" \n",
    "\n",
    "task_to_deeplift_contribs = OrderedDict()\n",
    "t0 = time.time()\n",
    "for task_idx in [2, 5, 8, 11]:\n",
    "    path = '../deeplift_scores/%s/contribs_reshaped_task%d.tab' % (modelName[:-1], task_idx)\n",
    "    task_to_deeplift_contribs[task_idx] = pd.read_csv(path, \n",
    "                                                      sep = '\\t',\n",
    "                                                      header = None).values\n",
    "    task_to_deeplift_contribs[task_idx] = task_to_deeplift_contribs[task_idx][:, 1:]\n",
    "    print task_to_deeplift_contribs[task_idx].shape\n",
    "    task_to_deeplift_contribs[task_idx] = np.reshape(task_to_deeplift_contribs[task_idx], (-1, 145, 4))\n",
    "    print(\"Reading in deepLIFT scores for task %d took %.3f sec\" % (task_idx, time.time() - t0))\n",
    "    t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "error getting worksize: CUDNN_STATUS_BAD_PARAM\nApply node that caused the error: GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuArrayConstant{[[[[ 0.  0.  0.  0.]\n   [ 5.  1.  0.  0.]\n   [ 0.  1.  3.  2.]\n   [ 0.  1.  0.  1.]]]\n\n\n [[[ 1.  0.  1.  0.]\n   [ 2.  3.  1.  0.]\n   [ 0.  0.  1.  5.]\n   [ 0.  0.  0.  0.]]]]}, GpuAllocEmpty{dtype='float32', context_name=None}.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float64'}.0, Constant{1.0}, Constant{0.0})\nToposort index: 23\nInputs types: [GpuArrayType<None>(float32, (False, False, False, False)), GpuArrayType<None>(float64, (False, True, False, False)), GpuArrayType<None>(float32, (False, False, False, False)), <theano.gof.type.CDataType object at 0x7fd88bd37650>, Scalar(float32), Scalar(float32)]\nInputs shapes: [(2, 1, 4, 9), (2, 1, 4, 4), (2, 2, 1, 6), 'No shapes', (), ()]\nInputs strides: [(144, 144, 36, 4), (128, 128, 32, 8), (48, 24, 24, 4), 'No strides', (), ()]\nInputs values: ['not shown', 'not shown', 'not shown', <capsule object NULL at 0x7fd88bc96e40>, 1.0, 0.0]\nOutputs clients: [[GpuJoin(TensorConstant{2}, GpuDnnConv{algo='small', inplace=True}.0, GpuDnnConv{algo='small', inplace=True}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c985bdc85ad4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m scanning_results = np.array(modisco.util.scan_regions_with_filters(\n\u001b[1;32m     32\u001b[0m     \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     regions_to_scan=regions_to_scan))\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscanning_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/users/rmovva/git/modisco_private/modisco/util.pyc\u001b[0m in \u001b[0;36mscan_regions_with_filters\u001b[0;34m(filters, regions_to_scan, batch_size, progress_update)\u001b[0m\n\u001b[1;32m    497\u001b[0m                             \u001b[0minput_data_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mregions_to_scan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                             progress_update=progress_update))\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconv_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/users/rmovva/git/deeplift/deeplift/util.pyc\u001b[0m in \u001b[0;36mrun_function_in_batches\u001b[0;34m(func, input_data_list, learning_phase, batch_size, progress_update, multimodal_output)\u001b[0m\n\u001b[1;32m     97\u001b[0m         func_output = func(*([x[i:i+batch_size] for x in input_data_list]\n\u001b[1;32m     98\u001b[0m                                 +([] if learning_phase is\n\u001b[0;32m---> 99\u001b[0;31m                                    None else [learning_phase])\n\u001b[0m\u001b[1;32m    100\u001b[0m                         ))\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmultimodal_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/users/rmovva/anaconda2/envs/newtheano/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/users/rmovva/anaconda2/envs/newtheano/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/users/rmovva/anaconda2/envs/newtheano/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: error getting worksize: CUDNN_STATUS_BAD_PARAM\nApply node that caused the error: GpuDnnConv{algo='small', inplace=True}(GpuContiguous.0, GpuArrayConstant{[[[[ 0.  0.  0.  0.]\n   [ 5.  1.  0.  0.]\n   [ 0.  1.  3.  2.]\n   [ 0.  1.  0.  1.]]]\n\n\n [[[ 1.  0.  1.  0.]\n   [ 2.  3.  1.  0.]\n   [ 0.  0.  1.  5.]\n   [ 0.  0.  0.  0.]]]]}, GpuAllocEmpty{dtype='float32', context_name=None}.0, GpuDnnConvDesc{border_mode='valid', subsample=(1, 1), conv_mode='conv', precision='float64'}.0, Constant{1.0}, Constant{0.0})\nToposort index: 23\nInputs types: [GpuArrayType<None>(float32, (False, False, False, False)), GpuArrayType<None>(float64, (False, True, False, False)), GpuArrayType<None>(float32, (False, False, False, False)), <theano.gof.type.CDataType object at 0x7fd88bd37650>, Scalar(float32), Scalar(float32)]\nInputs shapes: [(2, 1, 4, 9), (2, 1, 4, 4), (2, 2, 1, 6), 'No shapes', (), ()]\nInputs strides: [(144, 144, 36, 4), (128, 128, 32, 8), (48, 24, 24, 4), 'No strides', (), ()]\nInputs values: ['not shown', 'not shown', 'not shown', <capsule object NULL at 0x7fd88bc96e40>, 1.0, 0.0]\nOutputs clients: [[GpuJoin(TensorConstant{2}, GpuDnnConv{algo='small', inplace=True}.0, GpuDnnConv{algo='small', inplace=True}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import modisco\n",
    "import modisco.util\n",
    "import time\n",
    "\n",
    "regions_to_scan = np.array([[\n",
    "    [[0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "     [0.0, 0.0, 0.0, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0],\n",
    "     [0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.2, 0.0, 0.0],\n",
    "     [0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.0, 0.0]]\n",
    "],[\n",
    "    [[0.0, 0.0, 0.0, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "     [0.0, 0.0, 0.2, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0],\n",
    "     [0.0, 0.0, 0.0, 0.0, 0.4, 0.5, 0.0, 0.0, 0.0],\n",
    "     [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0]]\n",
    "]])\n",
    "filters = np.array([[\n",
    "    [1.0, 0.0, 1.0, 0.0],\n",
    "    [2.0, 3.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 1.0, 5.0],\n",
    "    [0.0, 0.0, 0.0, 0.0]\n",
    "],[\n",
    "    [0.0, 0.0, 0.0, 0.0],\n",
    "    [5.0, 1.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 3.0, 2.0],\n",
    "    [0.0, 1.0, 0.0, 1.0]\n",
    "]])\n",
    "\n",
    "scanning_results = np.array(modisco.util.scan_regions_with_filters(\n",
    "    filters=filters,\n",
    "    regions_to_scan=regions_to_scan))\n",
    "\n",
    "print(scanning_results)\n",
    "#fwd scan: [0.5, 1.1, 1.9, 3.7, 1.0, 0.0]\n",
    "#rev scan: [0.2, 0.3, 0.6, 3.3, 2.9, 0.2]\n",
    "correct_answer = np.array([[[\n",
    "                [0.5, 1.1, 1.9, 3.7, 2.9, 0.2],\n",
    "                [0,   0,   0,   0,   1,   1]\n",
    "            ],[\n",
    "                [0.5, 1.1, 1.9, 3.7, 2.9, 0.2],\n",
    "                [1,   1,   1,   1,   0,   0]\n",
    "            ],\n",
    "          ],[\n",
    "                [[0.2, 2.9, 3.7, 1.9, 1.1, 0.5],\n",
    "                 [0,   0,   1,   1,   1,   1]],\n",
    "                [[0.2, 2.9, 3.7, 1.9, 1.1, 0.5],\n",
    "                 [1,   1,   0,   0,   0,   0]]\n",
    "          ]])\n",
    "np.testing.assert_allclose(scanning_results, correct_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing around with TF PWM-sequence convolutions\n",
    "\n",
    "Familiarizing myself with the PWM loading code, playing with scipy's convolve function to make sure we can first just find enriched HOMER motifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "\n",
    "motifpwms = {}\n",
    "\n",
    "homer_path = '../../data/motifs/homer/*.motif'\n",
    "t0 = time.time()\n",
    "for homer_file in glob.glob(homer_path):\n",
    "    with open(homer_file) as f:\n",
    "        header = f.readline().strip().split('\\t')\n",
    "        name = header[1]\n",
    "        threshold = float(header[2])\n",
    "        weights = np.array(pd.read_csv(f, sep = '\\t'))\n",
    "        motifpwms[name] = weights\n",
    "print(\"Took %.3f sec to load HOMER motifs\" % (time.time() - t0))\n",
    "    \n",
    "# encode_motifs = '../../data/motifs/encode/motifs.txt'\n",
    "# t0 = time.time()\n",
    "# with open(encode_motifs) as fp:\n",
    "#     line = fp.readline().strip()\n",
    "#     while True:\n",
    "#         if line == '':\n",
    "#             break\n",
    "#         header = line\n",
    "#         weights = []\n",
    "#         while True:\n",
    "#             line = fp.readline()\n",
    "#             if line == '' or line[0] == '>':\n",
    "#                 break\n",
    "#             weights.append(map(float, line.split()[1:]))\n",
    "#         motifpwms[header] = np.array(weights)\n",
    "# print(\"Took %.3f sec to load ENCODE motifs\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "train_data_path = '../hdf5files/sharpr_znormed_jul23/train_data.hdf5'\n",
    "data = h5py.File(train_data_path)\n",
    "\n",
    "data_X = np.array(data['X/sequence'])\n",
    "data_Y = np.array(data['Y/output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import convolve\n",
    "\n",
    "motifs = motifpwms.keys()\n",
    "pwms = np.array([motifpwms[motif].astype(np.float32) for motif in motifs])\n",
    "\n",
    "conv_matrix = np.ndarray((len(data_X), len(motifs)))\n",
    "background_conv_matrix = np.ndarray((len(data_X), len(motifs)))\n",
    "\n",
    "idxs = np.argsort(data_Y[:, 2])[::-1][:500]\n",
    "bckgrnd_idxs = np.argsort(np.abs(data_Y[:, 2]))[:500]\n",
    "\n",
    "t0 = time.time()\n",
    "t1 = time.time()\n",
    "progress_update = 100\n",
    "# for (i, seq) in enumerate(data_X):\n",
    "for (i, idx) in enumerate(np.concatenate((idxs,bckgrnd_idxs))):\n",
    "#     if i % 31 != 0:\n",
    "#         continue\n",
    "    if i > 3000:\n",
    "        break\n",
    "    if i % progress_update == 0 and i > 0:\n",
    "        print(\"Seqs %d to %d took %.3f sec\" % (i - progress_update, i, time.time() - t1))\n",
    "        t1 = time.time()\n",
    "    for (j, pwm) in enumerate(pwms):\n",
    "        if idx in idxs:\n",
    "            max_conv = np.max(convolve(data_X[idx], pwms[j], mode = 'valid').ravel())\n",
    "            conv_matrix[idx][j] = max_conv\n",
    "        elif idx in bckgrnd_idxs:\n",
    "            max_conv = np.max(convolve(data_X[idx], pwms[j], mode = 'valid').ravel())\n",
    "            background_conv_matrix[idx][j] = max_conv\n",
    "        \n",
    "print(\"All convolutions took %.3f sec\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print np.sum(conv_matrix, axis = 0)\n",
    "# print np.sum(background_conv_matrix, axis = 0)\n",
    "motifScores = np.sum(conv_matrix, axis = 0) / np.sum(background_conv_matrix, axis = 0)\n",
    "sorted_idxs = np.argsort(motifScores)[::-1]\n",
    "sortedMotifs = np.array(motifs)[sorted_idxs]\n",
    "print motifScores[sorted_idxs[:10]]\n",
    "print sortedMotifs[:10]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:newtheano]",
   "language": "python",
   "name": "conda-env-newtheano-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
